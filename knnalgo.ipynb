{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mcjhk-hDYZ1"
      },
      "source": [
        "# Lab Experiment 1 - Nearest Neighbour Algorithm\n",
        "### Name                    :  Anurag Subramaniyan\n",
        "### Exam Registration Number:  24011103005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuwX-rXjDgGI"
      },
      "outputs": [],
      "source": [
        "### Exam Registration Number\n",
        "reg_no= 24011103005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFclHDCs9OKa"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "k-NN Algorithm:\n",
        "1. Compute distance from testX to all training points\n",
        "2. Sort based on distance\n",
        "3. Select k nearest neighbour\n",
        "4. Prediction:\n",
        "  a) Regression → mean\n",
        "  b) Classification → Majority voting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pY-V9SY-w4i"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "  dist = 0\n",
        "  ## Your Code Goes Here\n",
        "  dist += ((x2[0] - x1[0])**2) + ((x2[1] - x1[1])**2)\n",
        "  dist = dist**0.5\n",
        "  ##\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I46gSCKu__Xq"
      },
      "outputs": [],
      "source": [
        "def manhattan_distance(x1, x2):\n",
        "  dist = 0\n",
        "  ## Your Code Goes Here\n",
        "  man_length = len(x1)\n",
        "  for i in range(man_length):\n",
        "    dist += abs(x2[i]-x1[i])\n",
        "  ##\n",
        "  return dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwDNKqMqC7J4"
      },
      "outputs": [],
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "    correct = 0\n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        if yt == yp:\n",
        "            correct += 1\n",
        "    return correct / len(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XFb-1DzDO6q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Helper function to get unique train setting\n",
        "def train_test_split(X, Y, test_size=0.1):\n",
        "    random.seed(reg_no)\n",
        "\n",
        "    indices = list(range(len(X)))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    test_count = int(len(X) * test_size)\n",
        "\n",
        "    test_idx = indices[:test_count]\n",
        "    train_idx = indices[test_count:]\n",
        "\n",
        "    X_train = [X[i] for i in train_idx]\n",
        "    Y_train = [Y[i] for i in train_idx]\n",
        "\n",
        "    X_test = [X[i] for i in test_idx]\n",
        "    Y_test = [Y[i] for i in test_idx]\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHdsv3QB9vCE"
      },
      "outputs": [],
      "source": [
        "## Write your own code for k-Nearest Neighbour Algorithm\n",
        "def nearest_neighbour(X,Y,testX, k=3,is_classification=True):\n",
        "  \"\"\" [1]\n",
        "  X  : Training features (list of lists)\n",
        "  Y  : Training labels (list)\n",
        "  testX : Single test data point (list)\n",
        "  k  : Number of neighbours\n",
        "  is_classification : True for classification, False for regression\n",
        "  \"\"\"\n",
        "  ## Your Code Goes Here\n",
        "  ansY = None\n",
        "  dist_list = []\n",
        "  for i in range(len(X)):\n",
        "    dist_list.append(manhattan_distance(X[i],testX))\n",
        "  if(k == 1 and is_classification==True):\n",
        "    min_dist = min(dist_list)\n",
        "    min_idx = 0\n",
        "    for i in range(len(dist_list)):\n",
        "      if dist_list[i] == min_dist:\n",
        "        min_idx = i\n",
        "    ansY = Y[min_idx]\n",
        "  elif((k>1) and is_classification==True):\n",
        "     new_distances = sorted(dist_list)\n",
        "     top_distances = []\n",
        "     for i in range(k):\n",
        "      top_distances.append(new_distances[i])\n",
        "     top_dist_indexes = []\n",
        "     for j in top_distances:\n",
        "        for p in range(len(dist_list)):\n",
        "          if dist_list[p] == j:\n",
        "            top_dist_indexes.append(p)\n",
        "            break\n",
        "     top_labels = []\n",
        "     for i in range(len(top_dist_indexes)):\n",
        "       top_labels.append(Y[top_dist_indexes[i]])\n",
        "     unique_labels = []\n",
        "     for label in top_labels:\n",
        "       if label not in unique_labels:\n",
        "          unique_labels.append(label)\n",
        "     label_count = {}\n",
        "     for l in unique_labels:\n",
        "       label_count[l] = top_labels.count(l)\n",
        "     majority_label = max(label_count,key=label_count.get)\n",
        "     ansY = majority_label\n",
        "  else:\n",
        "    sorted_distances = sorted(dist_list)\n",
        "    top_distances = []\n",
        "    for i in range(k):\n",
        "      top_distances.append(sorted_distances[i])\n",
        "    dist_sum = 0\n",
        "    top_dist_indexes = []\n",
        "    for distance in top_distances:\n",
        "      for i in range(len(dist_list)):\n",
        "        if(dist_list[i] == distance and i not in top_dist_indexes):\n",
        "          top_dist_indexes.append(i)\n",
        "          break\n",
        "    for index in top_dist_indexes:\n",
        "      dist_sum += Y[index]\n",
        "    ansY = dist_sum / k\n",
        "  return ansY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfkCn4r1Ays4"
      },
      "outputs": [],
      "source": [
        "## Test case 1\n",
        "X = [\n",
        "    [1, 2],\n",
        "    [2, 3],\n",
        "    [3, 3],\n",
        "    [6, 5],\n",
        "    [7, 7],\n",
        "    [8, 6]\n",
        "]\n",
        "\n",
        "Y = ['A', 'A', 'A', 'B', 'B', 'B']\n",
        "testX = [3, 4]\n",
        "prediction = nearest_neighbour(X, Y, testX, k=1, is_classification=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzeu_9cVAE8y"
      },
      "outputs": [],
      "source": [
        "## Test case 2\n",
        "X = [\n",
        "    [1, 2],\n",
        "    [2, 3],\n",
        "    [3, 3],\n",
        "    [6, 5],\n",
        "    [7, 7],\n",
        "    [8, 6]\n",
        "]\n",
        "\n",
        "Y = ['A', 'A', 'A', 'B', 'B', 'B']\n",
        "\n",
        "testX = [3, 4]\n",
        "prediction = nearest_neighbour(X, Y, testX, k=3, is_classification=True)\n",
        "print(\"Predicted Class:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuudsOWYAne-"
      },
      "outputs": [],
      "source": [
        "## Test case 3\n",
        "X = [\n",
        "    [1],\n",
        "    [2],\n",
        "    [3],\n",
        "    [4],\n",
        "    [5]\n",
        "]\n",
        "\n",
        "Y = [2, 4, 6, 8, 10]   # y = 2x\n",
        "\n",
        "testX = [3.5]\n",
        "prediction = nearest_neighbour(X, Y, testX, k=2, is_classification=False)\n",
        "print(\"Predicted Value:\", prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUuKddrL9pti"
      },
      "source": [
        "## Question 1:\n",
        "Consider the dataset1.csv, How does the test accuracy of the kNN classifier vary as the number of training examples increases while keeping the test set size fixed at 10%?\n",
        "\n",
        "Write your insights with appropriate plots.\n",
        "Use the helper functions given above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYoH6fBC8u1o"
      },
      "outputs": [],
      "source": [
        "## Your Code Goes Here\n",
        "\n",
        "#To extract the contents of dataset1.csv\n",
        "\n",
        "import csv\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "label_map = {\n",
        "    'Iris-setosa': 0,\n",
        "    'Iris-versicolor': 1,\n",
        "    'Iris-virginica': 2\n",
        "}\n",
        "\n",
        "with open('/content/dataset1.csv', 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "\n",
        "    for row in reader:\n",
        "        X.append([\n",
        "            float(row[1]),\n",
        "            float(row[2]),\n",
        "            float(row[3]),\n",
        "            float(row[4])\n",
        "        ])\n",
        "        Y.append(label_map[row[5]])\n",
        "\n",
        "X_train , X_test , Y_train , Y_test = train_test_split(X,Y)\n",
        "\n",
        "training_samples_used = [20,40,80,135] #number of training samples we will use in each test first will be 20 , then 40....\n",
        "\n",
        "for number_of_samples in training_samples_used:\n",
        "    X_training_pool = X_train[:number_of_samples]\n",
        "    Y_training_pool = Y_train[:number_of_samples]\n",
        "    Y_predicted = []\n",
        "    for testX in X_test:\n",
        "       predicted_value = nearest_neighbour(X_training_pool,Y_training_pool,testX,k=3,is_classification=True)\n",
        "       Y_predicted.append(predicted_value)\n",
        "\n",
        "    acc_score = accuracy_score(Y_test,Y_predicted)\n",
        "    print(acc_score)\n",
        "##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y2a5VyIBBM_"
      },
      "source": [
        "## Question 2:\n",
        "Consider the dataset1.csv, How does changing the value of k influence the test accuracy of the kNN classifier, and what does this reveal about the bias-variance trade-off?\n",
        "\n",
        "Write your insights with appropriate plots.\n",
        "Use the helper functions given above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dZdEu-ABC9Y"
      },
      "outputs": [],
      "source": [
        "## Your Code Goes\n",
        "\n",
        "k_values = [1,3,5,7,9,11,13]\n",
        "\n",
        "for k in k_values:\n",
        "   Y_pred = []\n",
        "   for testX in X_test:\n",
        "     predicted_value = nearest_neighbour(X_train,Y_train,testX,k,is_classification=True)\n",
        "     Y_pred.append(predicted_value)\n",
        "\n",
        "   acc_score =  accuracy_score(Y_test,Y_pred)\n",
        "   print(acc_score)\n",
        "\n",
        "\n",
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP9qQXd6BeD1"
      },
      "source": [
        "## Question 3: (OPTIONAL)\n",
        "Draw voronoi diagram for any two features for k values - 1, 2 and 3.\n",
        "\n",
        "You may explore how to draw this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iRd1qhWBdY8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}